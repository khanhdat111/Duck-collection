{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7256393,"sourceType":"datasetVersion","datasetId":4204942}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from keras.layers import BatchNormalization, add\nfrom keras.layers import Conv2D\n\nkernel_initializer = 'he_uniform'\n\n\ndef conv_block_2D(x, filters, block_type, repeat=1, dilation_rate=1, size=3, padding='same'):\n    result = x\n\n    for i in range(0, repeat):\n\n        if block_type == 'separated':\n            result = separated_conv2D_block(result, filters, size=size, padding=padding)\n        elif block_type == 'duckv2':\n            result = duckv2_conv2D_block(result, filters, size=size)\n        elif block_type == 'midscope':\n            result = midscope_conv2D_block(result, filters)\n        elif block_type == 'widescope':\n            result = widescope_conv2D_block(result, filters)\n        elif block_type == 'resnet':\n            result = resnet_conv2D_block(result, filters, dilation_rate)\n        elif block_type == 'conv':\n            result = Conv2D(filters, (size, size),\n                            activation='relu', kernel_initializer=kernel_initializer, padding=padding)(result)\n        elif block_type == 'double_convolution':\n            result = double_convolution_with_batch_normalization(result, filters, dilation_rate)\n\n        else:\n            return None\n\n    return result\n\n\ndef duckv2_conv2D_block(x, filters, size):\n    x = BatchNormalization(axis=-1)(x)\n    x1 = widescope_conv2D_block(x, filters)\n\n    x2 = midscope_conv2D_block(x, filters)\n\n    x3 = conv_block_2D(x, filters, 'resnet', repeat=1)\n\n    x4 = conv_block_2D(x, filters, 'resnet', repeat=2)\n\n    x5 = conv_block_2D(x, filters, 'resnet', repeat=3)\n\n    x6 = separated_conv2D_block(x, filters, size=6, padding='same')\n\n    x = add([x1, x2, x3, x4, x5, x6])\n\n    x = BatchNormalization(axis=-1)(x)\n\n    return x\n\n\ndef separated_conv2D_block(x, filters, size=3, padding='same'):\n    x = Conv2D(filters, (1, size), activation='relu', kernel_initializer=kernel_initializer, padding=padding)(x)\n\n    x = BatchNormalization(axis=-1)(x)\n\n    x = Conv2D(filters, (size, 1), activation='relu', kernel_initializer=kernel_initializer, padding=padding)(x)\n\n    x = BatchNormalization(axis=-1)(x)\n\n    return x\n\n\ndef midscope_conv2D_block(x, filters):\n    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n               dilation_rate=1)(x)\n\n    x = BatchNormalization(axis=-1)(x)\n\n    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n               dilation_rate=2)(x)\n\n    x = BatchNormalization(axis=-1)(x)\n\n    return x\n\n\ndef widescope_conv2D_block(x, filters):\n    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n               dilation_rate=1)(x)\n\n    x = BatchNormalization(axis=-1)(x)\n\n    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n               dilation_rate=2)(x)\n\n    x = BatchNormalization(axis=-1)(x)\n\n    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n               dilation_rate=3)(x)\n\n    x = BatchNormalization(axis=-1)(x)\n\n    return x\n\n\ndef resnet_conv2D_block(x, filters, dilation_rate=1):\n    x1 = Conv2D(filters, (1, 1), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n                dilation_rate=dilation_rate)(x)\n\n    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n               dilation_rate=dilation_rate)(x)\n    x = BatchNormalization(axis=-1)(x)\n    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n               dilation_rate=dilation_rate)(x)\n    x = BatchNormalization(axis=-1)(x)\n    x_final = add([x, x1])\n\n    x_final = BatchNormalization(axis=-1)(x_final)\n\n    return x_final\n\n\ndef double_convolution_with_batch_normalization(x, filters, dilation_rate=1):\n    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n               dilation_rate=dilation_rate)(x)\n    x = BatchNormalization(axis=-1)(x)\n    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n               dilation_rate=dilation_rate)(x)\n    x = BatchNormalization(axis=-1)(x)\n\n    return x","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-26T18:36:52.812358Z","iopub.execute_input":"2023-12-26T18:36:52.813414Z","iopub.status.idle":"2023-12-26T18:37:03.822442Z","shell.execute_reply.started":"2023-12-26T18:36:52.813380Z","shell.execute_reply":"2023-12-26T18:37:03.821666Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras import layers\nfrom tensorflow.keras import backend as K\n\n#gating signal for attention unit\ndef gatingsignal(input, out_size, batchnorm=False):\n    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)\n    if batchnorm:\n        x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    return x\n\n#attention unit/block based on soft attention\ndef attention_block(x, gating, inter_shape):\n    shape_x = K.int_shape(x)\n    shape_g = K.int_shape(gating)\n    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), kernel_initializer='he_normal', padding='same')(x) \n    shape_theta_x = K.int_shape(theta_x)\n    phi_g = layers.Conv2D(inter_shape, (1, 1), kernel_initializer='he_normal', padding='same')(gating)\n    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3), strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]), kernel_initializer='he_normal', padding='same')(phi_g)\n    concat_xg = layers.add([upsample_g, theta_x])\n    act_xg = layers.Activation('relu')(concat_xg)\n    psi = layers.Conv2D(1, (1, 1), kernel_initializer='he_normal', padding='same')(act_xg)\n    sigmoid_xg = layers.Activation('sigmoid')(psi)\n    shape_sigmoid = K.int_shape(sigmoid_xg)\n    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg) \n    upsample_psi = layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3), arguments={'repnum': shape_x[3]})(upsample_psi)                          \n    y = layers.multiply([upsample_psi, x])\n    result = layers.Conv2D(shape_x[3], (1, 1), kernel_initializer='he_normal', padding='same')(y)\n    attenblock = layers.BatchNormalization()(result)\n    return attenblock","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:14:56.878796Z","iopub.execute_input":"2023-12-26T19:14:56.879197Z","iopub.status.idle":"2023-12-26T19:14:56.891512Z","shell.execute_reply.started":"2023-12-26T19:14:56.879163Z","shell.execute_reply":"2023-12-26T19:14:56.890548Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.layers import add\nfrom keras.models import Model\nfrom keras.layers import Conv2D, UpSampling2D\n\n\nkernel_initializer = 'he_uniform'\ninterpolation = \"nearest\"\n\n\ndef create_model_ver2(img_height, img_width, input_chanels, out_classes, starting_filters):\n    input_layer = tf.keras.layers.Input((img_height, img_width, input_chanels))\n\n    print('Starting DUCK-Net')\n    t0 = conv_block_2D(input_layer, starting_filters, 'duckv2', repeat=1)\n\n    l1i = Conv2D(starting_filters * 2, 2, strides=2, padding='same')(t0)\n    t1 = conv_block_2D(l1i, starting_filters * 2, 'duckv2', repeat=1)\n\n    l2i = Conv2D(starting_filters * 4, 2, strides=2, padding='same')(t1)\n    t2 = conv_block_2D(l2i, starting_filters * 4, 'duckv2', repeat=1)\n\n    l3i = Conv2D(starting_filters * 8, 2, strides=2, padding='same')(t2)\n    t3 = conv_block_2D(l3i, starting_filters * 8, 'duckv2', repeat=1)\n\n    l4i = Conv2D(starting_filters * 16, 2, strides=2, padding='same')(t3)\n    t4 = conv_block_2D(l4i, starting_filters * 16, 'duckv2', repeat=1)\n\n    l5i = Conv2D(starting_filters * 32, 2, strides=2, padding='same')(t4)\n    t51 = conv_block_2D(l5i, starting_filters * 32, 'resnet', repeat=2)\n    t53 = conv_block_2D(t51, starting_filters * 16, 'resnet', repeat=2)\n    \n    #--------------------------------------------------------------------#\n    \n    gating_5 = gatingsignal(t53, starting_filters * 16 , batchnorm=True)\n    att_5 = attention_block(t4, gating_5, starting_filters *16 )\n    l5o = UpSampling2D((2, 2), interpolation=interpolation)(t53)\n    print(l5o.shape)\n    print(att_5.shape)\n    #c4 = add([l5o, t4])\n    c4 = add([l5o, att_5])\n    #q4 = conv_block_2D(c4, starting_filters * 8, 'duckv2', repeat=1)\n    q4 = conv_block_2D(c4, starting_filters * 8, 'duckv2', repeat=1)\n\n    gating_4 = gatingsignal(q4,starting_filters * 8 , batchnorm=True)\n    att_4 = attention_block(t3, gating_4, starting_filters * 8 )\n    l4o = UpSampling2D((2, 2), interpolation=interpolation)(q4)\n    print(l4o.shape)\n    print(att_4.shape)\n    #c3 = add([l4o, t3])\n    #q3 = conv_block_2D(c3, starting_filters * 4, 'duckv2', repeat=1)\n    c3 = add([l4o, att_4])\n    q3 = conv_block_2D(c3, starting_filters * 4, 'duckv2', repeat=1)\n    \n    gating_3 = gatingsignal(q3,starting_filters * 4, batchnorm=True)\n    att_3 = attention_block(t2, gating_3, starting_filters * 4)\n    l3o = UpSampling2D((2, 2), interpolation=interpolation)(q3)\n    #c2 = add([l3o, t2])\n    #q6 = conv_block_2D(c2, starting_filters * 2, 'duckv2', repeat=1)\n    c2 = add([l3o, att_3])\n    q6 = conv_block_2D(c2, starting_filters * 2, 'duckv2', repeat=1)\n    \n    gating_2 = gatingsignal(q6 , starting_filters * 2, batchnorm=True)\n    att_2 = attention_block(t1, gating_2, starting_filters * 2)\n    l2o = UpSampling2D((2, 2), interpolation=interpolation)(q6)\n    #c1 = add([l2o, t1])\n    #q1 = conv_block_2D(c1, starting_filters, 'duckv2', repeat=1)\n    c1 = add([l2o, att_2])\n    q1 = conv_block_2D(c1, starting_filters , 'duckv2', repeat=1)\n    \n    \n    gating_1 = gatingsignal(q1 , starting_filters, batchnorm=True)\n    att_1 = attention_block(t0, gating_1, starting_filters)\n    l1o = UpSampling2D((2, 2), interpolation=interpolation)(q1)\n    #c0 = add([l1o, t0])\n    #z1 = conv_block_2D(c0, starting_filters, 'duckv2', repeat=1)\n    c0 = add([l1o, att_1])\n    z1 = conv_block_2D(c0, starting_filters, 'duckv2', repeat=1)\n\n    output = Conv2D(out_classes, (1, 1), activation='sigmoid')(z1)\n\n    model = Model(inputs=input_layer, outputs=output)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:21:28.410263Z","iopub.execute_input":"2023-12-26T19:21:28.411115Z","iopub.status.idle":"2023-12-26T19:21:28.430569Z","shell.execute_reply.started":"2023-12-26T19:21:28.411084Z","shell.execute_reply":"2023-12-26T19:21:28.429593Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model = create_model_ver2(img_height=256, img_width=256, input_chanels=3, out_classes=1, starting_filters=34)","metadata":{"execution":{"iopub.status.busy":"2023-12-26T20:23:49.033674Z","iopub.execute_input":"2023-12-26T20:23:49.034072Z","iopub.status.idle":"2023-12-26T20:23:55.642214Z","shell.execute_reply.started":"2023-12-26T20:23:49.034040Z","shell.execute_reply":"2023-12-26T20:23:55.641377Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Starting DUCK-Net\n(None, 16, 16, 544)\n(None, 16, 16, 544)\n(None, 32, 32, 272)\n(None, 32, 32, 272)\n","output_type":"stream"}]},{"cell_type":"code","source":"import keras.backend as K\nimport tensorflow as tf\n\n\ndef dice_metric_loss(ground_truth, predictions, smooth=1e-6):\n    ground_truth = K.cast(ground_truth, tf.float32)\n    predictions = K.cast(predictions, tf.float32)\n    ground_truth = K.flatten(ground_truth)\n    predictions = K.flatten(predictions)\n    intersection = K.sum(predictions * ground_truth)\n    union = K.sum(predictions) + K.sum(ground_truth)\n\n    dice = (2. * intersection + smooth) / (union + smooth)\n\n    return 1 - dice","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:21:57.417039Z","iopub.execute_input":"2023-12-26T19:21:57.417396Z","iopub.status.idle":"2023-12-26T19:21:57.423835Z","shell.execute_reply.started":"2023-12-26T19:21:57.417368Z","shell.execute_reply":"2023-12-26T19:21:57.422870Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\n\nimport numpy as np\nfrom PIL import Image\nfrom skimage.io import imread\nfrom tqdm import tqdm\n\nfolder_path = \"/kaggle/input/cvc-clinic-png/\"  # Add the path to your data directory\n\n\ndef load_data(img_height, img_width, images_to_be_loaded, dataset):\n    IMAGES_PATH = folder_path + 'Original/'\n    MASKS_PATH = folder_path + 'Ground Truth/'\n\n    if dataset == 'kvasir':\n        train_ids = glob.glob(IMAGES_PATH + \"*.jpg\")\n\n    if dataset == 'cvc-clinicdb':\n        train_ids = glob.glob(IMAGES_PATH + \"*.png\")\n        #train_ids = train_ids[:30]\n\n    if dataset == 'cvc-colondb' or dataset == 'etis-laribpolypdb':\n        train_ids = glob.glob(IMAGES_PATH + \"*.png\")\n\n    if images_to_be_loaded == -1:\n        images_to_be_loaded = len(train_ids)\n        print(images_to_be_loaded)\n\n    X_train = np.zeros((images_to_be_loaded, img_height, img_width, 3), dtype=np.float32)\n    Y_train = np.zeros((images_to_be_loaded, img_height, img_width), dtype=np.uint8)\n\n    print('Resizing training images and masks: ' + str(images_to_be_loaded))\n    for n, id_ in tqdm(enumerate(train_ids)):\n        if n == images_to_be_loaded:\n            break\n\n        image_path = id_\n        mask_path = image_path.replace(\"images\", \"masks\")\n\n        image = imread(image_path)\n        mask_ = imread(mask_path)\n\n        mask = np.zeros((img_height, img_width), dtype=np.bool_)\n\n        pillow_image = Image.fromarray(image)\n\n        pillow_image = pillow_image.resize((img_height, img_width))\n        image = np.array(pillow_image)\n\n        X_train[n] = image / 255\n\n        pillow_mask = Image.fromarray(mask_)\n        pillow_mask = pillow_mask.resize((img_height, img_width), resample=Image.LANCZOS)\n        mask_ = np.array(pillow_mask)\n\n        for i in range(img_height):\n            for j in range(img_width):\n                if (mask_[i, j] >= 127).all():\n                    mask[i, j] = 1\n\n        Y_train[n] = mask\n\n    Y_train = np.expand_dims(Y_train, axis=-1)\n\n    return X_train, Y_train","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:31:28.290871Z","iopub.execute_input":"2023-12-26T19:31:28.291264Z","iopub.status.idle":"2023-12-26T19:31:28.304860Z","shell.execute_reply.started":"2023-12-26T19:31:28.291234Z","shell.execute_reply":"2023-12-26T19:31:28.303817Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"X, Y = load_data(256, 256, -1, 'cvc-clinicdb')","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:31:30.947308Z","iopub.execute_input":"2023-12-26T19:31:30.947649Z","iopub.status.idle":"2023-12-26T19:35:54.961258Z","shell.execute_reply.started":"2023-12-26T19:31:30.947621Z","shell.execute_reply":"2023-12-26T19:35:54.960231Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"612\nResizing training images and masks: 612\n","output_type":"stream"},{"name":"stderr","text":"612it [04:23,  2.32it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, shuffle= True, random_state = 58800)\nx_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.111, shuffle= True, random_state = 58800)\nlen(x_valid)","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:38:02.916455Z","iopub.execute_input":"2023-12-26T19:38:02.916862Z","iopub.status.idle":"2023-12-26T19:38:03.212548Z","shell.execute_reply.started":"2023-12-26T19:38:02.916829Z","shell.execute_reply":"2023-12-26T19:38:03.211492Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"62"},"metadata":{}}]},{"cell_type":"code","source":"# Defining the augmentations\nimport albumentations as albu\naug_train = albu.Compose([\n    albu.HorizontalFlip(),\n    albu.VerticalFlip(),\n    albu.ColorJitter(brightness=(0.6,1.6), contrast=0.2, saturation=0.1, hue=0.01, always_apply=True),\n    albu.Affine(scale=(0.5,1.5), translate_percent=(-0.125,0.125), rotate=(-180,180), shear=(-22.5,22), always_apply=True),\n])\n\ndef augment_images():\n    x_train_out = []\n    y_train_out = []\n\n    for i in range (len(x_train)):\n        ug = aug_train(image=x_train[i], mask=y_train[i])\n        x_train_out.append(ug['image'])  \n        y_train_out.append(ug['mask'])\n\n    return np.array(x_train_out), np.array(y_train_out)","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:38:05.582394Z","iopub.execute_input":"2023-12-26T19:38:05.582769Z","iopub.status.idle":"2023-12-26T19:38:05.590768Z","shell.execute_reply.started":"2023-12-26T19:38:05.582737Z","shell.execute_reply":"2023-12-26T19:38:05.589723Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"image_augmented, mask_augmented = augment_images()","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:38:09.993808Z","iopub.execute_input":"2023-12-26T19:38:09.994181Z","iopub.status.idle":"2023-12-26T19:38:12.627095Z","shell.execute_reply.started":"2023-12-26T19:38:09.994152Z","shell.execute_reply":"2023-12-26T19:38:12.626265Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"len(image_augmented)","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:38:14.153435Z","iopub.execute_input":"2023-12-26T19:38:14.153803Z","iopub.status.idle":"2023-12-26T19:38:14.160211Z","shell.execute_reply.started":"2023-12-26T19:38:14.153772Z","shell.execute_reply":"2023-12-26T19:38:14.159216Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"488"},"metadata":{}}]},{"cell_type":"code","source":"learning_rate = 1e-4\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\nmodel.compile(optimizer=optimizer, loss=dice_metric_loss)","metadata":{"execution":{"iopub.status.busy":"2023-12-26T20:28:53.864366Z","iopub.execute_input":"2023-12-26T20:28:53.865297Z","iopub.status.idle":"2023-12-26T20:28:53.899000Z","shell.execute_reply.started":"2023-12-26T20:28:53.865260Z","shell.execute_reply":"2023-12-26T20:28:53.898190Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"import gc\nEPOCHS = 100\nmin_loss_for_saving = 0.2\nstep = 0\n\nfor epoch in range(0, EPOCHS):\n    \n    print(f'Training, epoch {epoch}')\n    print('Learning Rate: ' + str(learning_rate))\n\n    step += 1\n    \n    model.fit(x=image_augmented, y=mask_augmented, epochs=1, batch_size=4, validation_data=(x_valid, y_valid), verbose=1)\n    \n    prediction_valid = model.predict(x_valid, verbose=0)\n    loss_valid = dice_metric_loss(y_valid, prediction_valid)\n    \n    loss_valid = loss_valid.numpy()\n    print(\"Loss Validation: \" + str(loss_valid))\n        \n    prediction_test = model.predict(x_test, verbose=0)\n    loss_test = dice_metric_loss(y_test, prediction_test)\n    loss_test = loss_test.numpy()\n    print(\"Loss Test: \" + str(loss_test))\n     \n    if min_loss_for_saving > loss_valid:\n        min_loss_for_saving = loss_valid\n        print(\"Saved model with val_loss: \", loss_valid)\n        model.save(\"/kaggle/working/duck-net-ver2.h5\")\n        \n    #del image_augmented\n    #del mask_augmented\n\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-12-26T20:28:56.433774Z","iopub.execute_input":"2023-12-26T20:28:56.434474Z","iopub.status.idle":"2023-12-26T23:03:01.832765Z","shell.execute_reply.started":"2023-12-26T20:28:56.434440Z","shell.execute_reply":"2023-12-26T23:03:01.831798Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Training, epoch 0\nLearning Rate: 0.0001\n122/122 [==============================] - 308s 742ms/step - loss: 0.8600 - val_loss: 0.9296\nLoss Validation: 0.7608582\nLoss Test: 0.6937314\nTraining, epoch 1\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 682ms/step - loss: 0.7887 - val_loss: 0.8215\nLoss Validation: 0.55297995\nLoss Test: 0.469436\nTraining, epoch 2\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 682ms/step - loss: 0.7585 - val_loss: 0.8782\nLoss Validation: 0.5673422\nLoss Test: 0.48513758\nTraining, epoch 3\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 681ms/step - loss: 0.7306 - val_loss: 0.4870\nLoss Validation: 0.54304546\nLoss Test: 0.43311596\nTraining, epoch 4\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 681ms/step - loss: 0.6980 - val_loss: 0.5285\nLoss Validation: 0.4967209\nLoss Test: 0.39099443\nTraining, epoch 5\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 681ms/step - loss: 0.6650 - val_loss: 0.4785\nLoss Validation: 0.45684242\nLoss Test: 0.37426567\nTraining, epoch 6\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.6311 - val_loss: 0.5080\nLoss Validation: 0.45028633\nLoss Test: 0.32604247\nTraining, epoch 7\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.5916 - val_loss: 0.6329\nLoss Validation: 0.4294352\nLoss Test: 0.33497876\nTraining, epoch 8\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.5498 - val_loss: 0.4498\nLoss Validation: 0.48786604\nLoss Test: 0.33823973\nTraining, epoch 9\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.5078 - val_loss: 0.3689\nLoss Validation: 0.30775338\nLoss Test: 0.22642732\nTraining, epoch 10\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.4829 - val_loss: 0.2808\nLoss Validation: 0.28933758\nLoss Test: 0.217682\nTraining, epoch 11\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.4432 - val_loss: 0.2551\nLoss Validation: 0.25179023\nLoss Test: 0.18283027\nTraining, epoch 12\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.4204 - val_loss: 0.3163\nLoss Validation: 0.3080207\nLoss Test: 0.18242478\nTraining, epoch 13\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.3685 - val_loss: 0.5258\nLoss Validation: 0.39076626\nLoss Test: 0.33072865\nTraining, epoch 14\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.3552 - val_loss: 0.2422\nLoss Validation: 0.1619609\nLoss Test: 0.11743957\nSaved model with val_loss:  0.1619609\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"Training, epoch 15\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 681ms/step - loss: 0.3107 - val_loss: 0.2063\nLoss Validation: 0.16859704\nLoss Test: 0.12307048\nTraining, epoch 16\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 681ms/step - loss: 0.3323 - val_loss: 0.2045\nLoss Validation: 0.1605863\nLoss Test: 0.11666906\nSaved model with val_loss:  0.1605863\nTraining, epoch 17\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 681ms/step - loss: 0.2881 - val_loss: 0.3439\nLoss Validation: 0.22244728\nLoss Test: 0.19429582\nTraining, epoch 18\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 681ms/step - loss: 0.2659 - val_loss: 0.1361\nLoss Validation: 0.1226024\nLoss Test: 0.098169506\nSaved model with val_loss:  0.1226024\nTraining, epoch 19\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.2563 - val_loss: 0.2159\nLoss Validation: 0.15461534\nLoss Test: 0.13084787\nTraining, epoch 20\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 681ms/step - loss: 0.2587 - val_loss: 0.2100\nLoss Validation: 0.17753142\nLoss Test: 0.14804322\nTraining, epoch 21\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.2554 - val_loss: 0.3334\nLoss Validation: 0.25323296\nLoss Test: 0.21773404\nTraining, epoch 22\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.2349 - val_loss: 0.1893\nLoss Validation: 0.16262221\nLoss Test: 0.1157698\nTraining, epoch 23\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.2257 - val_loss: 0.2485\nLoss Validation: 0.21232802\nLoss Test: 0.16744095\nTraining, epoch 24\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.2475 - val_loss: 0.2242\nLoss Validation: 0.18484658\nLoss Test: 0.14594692\nTraining, epoch 25\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.2140 - val_loss: 0.1742\nLoss Validation: 0.1504882\nLoss Test: 0.0824908\nTraining, epoch 26\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.2132 - val_loss: 0.1987\nLoss Validation: 0.15102792\nLoss Test: 0.1149897\nTraining, epoch 27\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.2074 - val_loss: 0.1993\nLoss Validation: 0.16320461\nLoss Test: 0.12982231\nTraining, epoch 28\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1994 - val_loss: 0.2050\nLoss Validation: 0.163786\nLoss Test: 0.12763822\nTraining, epoch 29\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1963 - val_loss: 0.2729\nLoss Validation: 0.24498135\nLoss Test: 0.19716519\nTraining, epoch 30\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.2203 - val_loss: 0.2375\nLoss Validation: 0.18959665\nLoss Test: 0.14333725\nTraining, epoch 31\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.2082 - val_loss: 0.1514\nLoss Validation: 0.151155\nLoss Test: 0.079803884\nTraining, epoch 32\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1882 - val_loss: 0.2243\nLoss Validation: 0.19991332\nLoss Test: 0.13041955\nTraining, epoch 33\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1927 - val_loss: 0.2650\nLoss Validation: 0.2323268\nLoss Test: 0.19132453\nTraining, epoch 34\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1775 - val_loss: 0.1745\nLoss Validation: 0.15337056\nLoss Test: 0.124094725\nTraining, epoch 35\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1789 - val_loss: 0.2053\nLoss Validation: 0.18523282\nLoss Test: 0.1390602\nTraining, epoch 36\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1792 - val_loss: 0.1568\nLoss Validation: 0.14121193\nLoss Test: 0.10648662\nTraining, epoch 37\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1759 - val_loss: 0.1900\nLoss Validation: 0.15369093\nLoss Test: 0.12090343\nTraining, epoch 38\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1856 - val_loss: 0.2188\nLoss Validation: 0.18261307\nLoss Test: 0.15054995\nTraining, epoch 39\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1827 - val_loss: 0.1684\nLoss Validation: 0.13643962\nLoss Test: 0.10072315\nTraining, epoch 40\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1751 - val_loss: 0.1788\nLoss Validation: 0.15153927\nLoss Test: 0.11308116\nTraining, epoch 41\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1688 - val_loss: 0.2965\nLoss Validation: 0.2539454\nLoss Test: 0.20611233\nTraining, epoch 42\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1709 - val_loss: 0.1309\nLoss Validation: 0.10979283\nLoss Test: 0.07557887\nSaved model with val_loss:  0.10979283\nTraining, epoch 43\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 681ms/step - loss: 0.1620 - val_loss: 0.1773\nLoss Validation: 0.15262246\nLoss Test: 0.11327934\nTraining, epoch 44\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1715 - val_loss: 0.1639\nLoss Validation: 0.15320301\nLoss Test: 0.114567995\nTraining, epoch 45\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1673 - val_loss: 0.2412\nLoss Validation: 0.19326395\nLoss Test: 0.16742611\nTraining, epoch 46\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1672 - val_loss: 0.2143\nLoss Validation: 0.199292\nLoss Test: 0.1542756\nTraining, epoch 47\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1721 - val_loss: 0.2100\nLoss Validation: 0.18061614\nLoss Test: 0.14487636\nTraining, epoch 48\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1683 - val_loss: 0.2746\nLoss Validation: 0.24006975\nLoss Test: 0.20046163\nTraining, epoch 49\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1594 - val_loss: 0.2230\nLoss Validation: 0.19248915\nLoss Test: 0.14109671\nTraining, epoch 50\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1614 - val_loss: 0.3443\nLoss Validation: 0.30555403\nLoss Test: 0.25314897\nTraining, epoch 51\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1683 - val_loss: 0.1948\nLoss Validation: 0.17387003\nLoss Test: 0.13456261\nTraining, epoch 52\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1639 - val_loss: 0.2096\nLoss Validation: 0.17745233\nLoss Test: 0.14264\nTraining, epoch 53\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1599 - val_loss: 0.2211\nLoss Validation: 0.19154114\nLoss Test: 0.16094047\nTraining, epoch 54\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1618 - val_loss: 0.1850\nLoss Validation: 0.16827536\nLoss Test: 0.140912\nTraining, epoch 55\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1465 - val_loss: 0.2451\nLoss Validation: 0.19701278\nLoss Test: 0.1686396\nTraining, epoch 56\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1621 - val_loss: 0.2008\nLoss Validation: 0.18034679\nLoss Test: 0.15349162\nTraining, epoch 57\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1509 - val_loss: 0.2193\nLoss Validation: 0.173338\nLoss Test: 0.14127475\nTraining, epoch 58\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1736 - val_loss: 0.1986\nLoss Validation: 0.1307106\nLoss Test: 0.11143541\nTraining, epoch 59\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1629 - val_loss: 0.2945\nLoss Validation: 0.20753688\nLoss Test: 0.17944187\nTraining, epoch 60\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1556 - val_loss: 0.1702\nLoss Validation: 0.12010759\nLoss Test: 0.09723228\nTraining, epoch 61\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1547 - val_loss: 0.2089\nLoss Validation: 0.1737625\nLoss Test: 0.12983716\nTraining, epoch 62\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1566 - val_loss: 0.2186\nLoss Validation: 0.15139067\nLoss Test: 0.13937712\nTraining, epoch 63\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1488 - val_loss: 0.1223\nLoss Validation: 0.12463361\nLoss Test: 0.0996331\nTraining, epoch 64\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1481 - val_loss: 0.1096\nLoss Validation: 0.10500085\nLoss Test: 0.07149029\nSaved model with val_loss:  0.10500085\nTraining, epoch 65\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 681ms/step - loss: 0.1530 - val_loss: 0.1697\nLoss Validation: 0.1485591\nLoss Test: 0.12407929\nTraining, epoch 66\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 681ms/step - loss: 0.1418 - val_loss: 0.2473\nLoss Validation: 0.2096963\nLoss Test: 0.16923112\nTraining, epoch 67\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1468 - val_loss: 0.1498\nLoss Validation: 0.11447859\nLoss Test: 0.08353251\nTraining, epoch 68\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1460 - val_loss: 0.1823\nLoss Validation: 0.14192683\nLoss Test: 0.104967594\nTraining, epoch 69\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1372 - val_loss: 0.1292\nLoss Validation: 0.112421334\nLoss Test: 0.07819462\nTraining, epoch 70\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1559 - val_loss: 0.2205\nLoss Validation: 0.17664182\nLoss Test: 0.13761294\nTraining, epoch 71\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1374 - val_loss: 0.1804\nLoss Validation: 0.15963215\nLoss Test: 0.13385272\nTraining, epoch 72\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1443 - val_loss: 0.1887\nLoss Validation: 0.16999769\nLoss Test: 0.13342047\nTraining, epoch 73\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1336 - val_loss: 0.1829\nLoss Validation: 0.16875648\nLoss Test: 0.14149928\nTraining, epoch 74\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1422 - val_loss: 0.1515\nLoss Validation: 0.1265701\nLoss Test: 0.10042322\nTraining, epoch 75\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1532 - val_loss: 0.1102\nLoss Validation: 0.09374654\nLoss Test: 0.07781249\nSaved model with val_loss:  0.09374654\nTraining, epoch 76\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 681ms/step - loss: 0.1499 - val_loss: 0.2068\nLoss Validation: 0.2018531\nLoss Test: 0.1666398\nTraining, epoch 77\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 681ms/step - loss: 0.1420 - val_loss: 0.1399\nLoss Validation: 0.12748015\nLoss Test: 0.100493014\nTraining, epoch 78\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1499 - val_loss: 0.1729\nLoss Validation: 0.15178835\nLoss Test: 0.120192826\nTraining, epoch 79\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1422 - val_loss: 0.1690\nLoss Validation: 0.14286351\nLoss Test: 0.11584121\nTraining, epoch 80\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1271 - val_loss: 0.1146\nLoss Validation: 0.09540826\nLoss Test: 0.07914156\nTraining, epoch 81\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1403 - val_loss: 0.0833\nLoss Validation: 0.070340276\nLoss Test: 0.057618797\nSaved model with val_loss:  0.070340276\nTraining, epoch 82\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 681ms/step - loss: 0.1575 - val_loss: 0.1287\nLoss Validation: 0.10838008\nLoss Test: 0.09281051\nTraining, epoch 83\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1377 - val_loss: 0.2066\nLoss Validation: 0.18275249\nLoss Test: 0.14044434\nTraining, epoch 84\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1403 - val_loss: 0.1550\nLoss Validation: 0.13153625\nLoss Test: 0.10619396\nTraining, epoch 85\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1433 - val_loss: 0.1653\nLoss Validation: 0.15035576\nLoss Test: 0.11535007\nTraining, epoch 86\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1291 - val_loss: 0.1544\nLoss Validation: 0.13102716\nLoss Test: 0.09341508\nTraining, epoch 87\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1459 - val_loss: 0.1133\nLoss Validation: 0.103916764\nLoss Test: 0.08083701\nTraining, epoch 88\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1338 - val_loss: 0.1520\nLoss Validation: 0.14373046\nLoss Test: 0.11754644\nTraining, epoch 89\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1423 - val_loss: 0.1408\nLoss Validation: 0.106004655\nLoss Test: 0.08552259\nTraining, epoch 90\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1337 - val_loss: 0.2445\nLoss Validation: 0.1992948\nLoss Test: 0.16767496\nTraining, epoch 91\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1532 - val_loss: 0.1298\nLoss Validation: 0.09866631\nLoss Test: 0.08294976\nTraining, epoch 92\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1388 - val_loss: 0.1618\nLoss Validation: 0.1542188\nLoss Test: 0.12625837\nTraining, epoch 93\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1259 - val_loss: 0.1085\nLoss Validation: 0.10854703\nLoss Test: 0.08737743\nTraining, epoch 94\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1386 - val_loss: 0.1407\nLoss Validation: 0.1335299\nLoss Test: 0.103608966\nTraining, epoch 95\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1368 - val_loss: 0.2877\nLoss Validation: 0.22197396\nLoss Test: 0.16745687\nTraining, epoch 96\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1380 - val_loss: 0.1953\nLoss Validation: 0.15091318\nLoss Test: 0.102540314\nTraining, epoch 97\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1406 - val_loss: 0.2058\nLoss Validation: 0.18921912\nLoss Test: 0.14220351\nTraining, epoch 98\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1227 - val_loss: 0.1509\nLoss Validation: 0.12399602\nLoss Test: 0.10386187\nTraining, epoch 99\nLearning Rate: 0.0001\n122/122 [==============================] - 83s 680ms/step - loss: 0.1349 - val_loss: 0.1501\nLoss Validation: 0.113318145\nLoss Test: 0.08680546\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import jaccard_score, precision_score, recall_score, accuracy_score, f1_score\nprint(\"Loading the model\")\n\nmodel = tf.keras.models.load_model('/kaggle/working/duck-net-ver2.h5', custom_objects={'dice_metric_loss':dice_metric_loss})\n\nprediction_train = model.predict(x_train, batch_size=4)\nprediction_valid = model.predict(x_valid, batch_size=4)\nprediction_test = model.predict(x_test, batch_size=4)\n\nprint(\"Predictions done\")\n\ndice_train = f1_score(np.ndarray.flatten(np.array(y_train, dtype=bool)),\n                           np.ndarray.flatten(prediction_train > 0.5))\ndice_test = f1_score(np.ndarray.flatten(np.array(y_test, dtype=bool)),\n                          np.ndarray.flatten(prediction_test > 0.5))\ndice_valid = f1_score(np.ndarray.flatten(np.array(y_valid, dtype=bool)),\n                           np.ndarray.flatten(prediction_valid > 0.5))\n\nprint(\"Dice finished\")\n\n\nmiou_train = jaccard_score(np.ndarray.flatten(np.array(y_train, dtype=bool)),\n                           np.ndarray.flatten(prediction_train > 0.5))\nmiou_test = jaccard_score(np.ndarray.flatten(np.array(y_test, dtype=bool)),\n                          np.ndarray.flatten(prediction_test > 0.5))\nmiou_valid = jaccard_score(np.ndarray.flatten(np.array(y_valid, dtype=bool)),\n                           np.ndarray.flatten(prediction_valid > 0.5))\n\nprint(\"Miou finished\")\n\n\nprecision_train = precision_score(np.ndarray.flatten(np.array(y_train, dtype=bool)),\n                                  np.ndarray.flatten(prediction_train > 0.5))\nprecision_test = precision_score(np.ndarray.flatten(np.array(y_test, dtype=bool)),\n                                 np.ndarray.flatten(prediction_test > 0.5))\nprecision_valid = precision_score(np.ndarray.flatten(np.array(y_valid, dtype=bool)),\n                                  np.ndarray.flatten(prediction_valid > 0.5))\n\nprint(\"Precision finished\")\n\n\nrecall_train = recall_score(np.ndarray.flatten(np.array(y_train, dtype=bool)),\n                            np.ndarray.flatten(prediction_train > 0.5))\nrecall_test = recall_score(np.ndarray.flatten(np.array(y_test, dtype=bool)),\n                           np.ndarray.flatten(prediction_test > 0.5))\nrecall_valid = recall_score(np.ndarray.flatten(np.array(y_valid, dtype=bool)),\n                            np.ndarray.flatten(prediction_valid > 0.5))\n\nprint(\"Recall finished\")\n\n\naccuracy_train = accuracy_score(np.ndarray.flatten(np.array(y_train, dtype=bool)),\n                                np.ndarray.flatten(prediction_train > 0.5))\naccuracy_test = accuracy_score(np.ndarray.flatten(np.array(y_test, dtype=bool)),\n                               np.ndarray.flatten(prediction_test > 0.5))\naccuracy_valid = accuracy_score(np.ndarray.flatten(np.array(y_valid, dtype=bool)),\n                                np.ndarray.flatten(prediction_valid > 0.5))\n\n\nprint(\"Accuracy finished\")\n\n\nfinal_file = '/kaggle/working/'+'results_'+'Attention_DUCK-Net'+ '.txt'\nprint(final_file)\n\nwith open(final_file, 'a') as f:\n    f.write('clinic-db' + '\\n\\n')\n    f.write('dice_train: ' + str(dice_train) + ' dice_valid: ' + str(dice_valid) + ' dice_test: ' + str(dice_test) + '\\n\\n')\n    f.write('miou_train: ' + str(miou_train) + ' miou_valid: ' + str(miou_valid) + ' miou_test: ' + str(miou_test) + '\\n\\n')\n    f.write('precision_train: ' + str(precision_train) + ' precision_valid: ' + str(precision_valid) + ' precision_test: ' + str(precision_test) + '\\n\\n')\n    f.write('recall_train: ' + str(recall_train) + ' recall_valid: ' + str(recall_valid) + ' recall_test: ' + str(recall_test) + '\\n\\n')\n    f.write('accuracy_train: ' + str(accuracy_train) + ' accuracy_valid: ' + str(accuracy_valid) + ' accuracy_test: ' + str(accuracy_test) + '\\n\\n\\n\\n')\n\nprint('File done')","metadata":{"execution":{"iopub.status.busy":"2023-12-26T23:05:31.425284Z","iopub.execute_input":"2023-12-26T23:05:31.425963Z","iopub.status.idle":"2023-12-26T23:07:15.777914Z","shell.execute_reply.started":"2023-12-26T23:05:31.425929Z","shell.execute_reply":"2023-12-26T23:07:15.776848Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Loading the model\n122/122 [==============================] - 28s 183ms/step\n16/16 [==============================] - 9s 183ms/step\n16/16 [==============================] - 3s 183ms/step\nPredictions done\nDice finished\nMiou finished\nPrecision finished\nRecall finished\nAccuracy finished\n/kaggle/working/results_Attention_DUCK-Net.txt\nFile done\n","output_type":"stream"}]}]}