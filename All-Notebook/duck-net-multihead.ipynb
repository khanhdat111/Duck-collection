{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7256393,"sourceType":"datasetVersion","datasetId":4204942}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import glob\n\nimport numpy as np\nfrom PIL import Image\nfrom skimage.io import imread\nfrom tqdm import tqdm\n\nfolder_path = \"/kaggle/input/cvc-clinic-png/\"  # Add the path to your data directory\n\n\ndef load_data(img_height, img_width, images_to_be_loaded, dataset):\n    IMAGES_PATH = folder_path + 'Original/'\n    MASKS_PATH = folder_path + 'Ground Truth/'\n\n    if dataset == 'kvasir':\n        train_ids = glob.glob(IMAGES_PATH + \"*.jpg\")\n\n    if dataset == 'cvc-clinicdb':\n        train_ids = glob.glob(IMAGES_PATH + \"*.png\")\n        #train_ids = train_ids[:30]\n\n    if dataset == 'cvc-colondb' or dataset == 'etis-laribpolypdb':\n        train_ids = glob.glob(IMAGES_PATH + \"*.png\")\n\n    if images_to_be_loaded == -1:\n        images_to_be_loaded = len(train_ids)\n        print(images_to_be_loaded)\n\n    X_train = np.zeros((images_to_be_loaded, img_height, img_width, 3), dtype=np.float32)\n    Y_train = np.zeros((images_to_be_loaded, img_height, img_width), dtype=np.uint8)\n\n    print('Resizing training images and masks: ' + str(images_to_be_loaded))\n    for n, id_ in tqdm(enumerate(train_ids)):\n        if n == images_to_be_loaded:\n            break\n\n        image_path = id_\n        mask_path = image_path.replace(\"images\", \"masks\")\n\n        image = imread(image_path)\n        mask_ = imread(mask_path)\n\n        mask = np.zeros((img_height, img_width), dtype=np.bool_)\n\n        pillow_image = Image.fromarray(image)\n\n        pillow_image = pillow_image.resize((img_height, img_width))\n        image = np.array(pillow_image)\n\n        X_train[n] = image / 255\n\n        pillow_mask = Image.fromarray(mask_)\n        pillow_mask = pillow_mask.resize((img_height, img_width), resample=Image.LANCZOS)\n        mask_ = np.array(pillow_mask)\n\n        for i in range(img_height):\n            for j in range(img_width):\n                if (mask_[i, j] >= 127).all():\n                    mask[i, j] = 1\n\n        Y_train[n] = mask\n\n    Y_train = np.expand_dims(Y_train, axis=-1)\n\n    return X_train, Y_train","metadata":{"execution":{"iopub.status.busy":"2024-01-22T17:36:34.701083Z","iopub.execute_input":"2024-01-22T17:36:34.701764Z","iopub.status.idle":"2024-01-22T17:36:34.873412Z","shell.execute_reply.started":"2024-01-22T17:36:34.701732Z","shell.execute_reply":"2024-01-22T17:36:34.872054Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"X, Y = load_data(256, 256, -1, 'cvc-clinicdb')","metadata":{"execution":{"iopub.status.busy":"2024-01-22T17:36:38.449058Z","iopub.execute_input":"2024-01-22T17:36:38.449869Z","iopub.status.idle":"2024-01-22T17:41:21.292635Z","shell.execute_reply.started":"2024-01-22T17:36:38.449833Z","shell.execute_reply":"2024-01-22T17:41:21.291673Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"612\nResizing training images and masks: 612\n","output_type":"stream"},{"name":"stderr","text":"612it [04:42,  2.16it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, shuffle= True, random_state = 58800)\nx_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.111, shuffle= True, random_state = 58800)\nlen(x_valid)","metadata":{"execution":{"iopub.status.busy":"2024-01-22T17:41:21.294535Z","iopub.execute_input":"2024-01-22T17:41:21.294843Z","iopub.status.idle":"2024-01-22T17:41:21.937272Z","shell.execute_reply.started":"2024-01-22T17:41:21.294816Z","shell.execute_reply":"2024-01-22T17:41:21.936290Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"62"},"metadata":{}}]},{"cell_type":"code","source":"# Defining the augmentations\nimport albumentations as albu\naug_train = albu.Compose([\n    albu.HorizontalFlip(),\n    albu.VerticalFlip(),\n    albu.ColorJitter(brightness=(0.6,1.6), contrast=0.2, saturation=0.1, hue=0.01, always_apply=True),\n    albu.Affine(scale=(0.5,1.5), translate_percent=(-0.125,0.125), rotate=(-180,180), shear=(-22.5,22), always_apply=True),\n])\n\ndef augment_images():\n    x_train_out = []\n    y_train_out = []\n\n    for i in range (len(x_train)):\n        ug = aug_train(image=x_train[i], mask=y_train[i])\n        x_train_out.append(ug['image'])  \n        y_train_out.append(ug['mask'])\n\n    return np.array(x_train_out), np.array(y_train_out)","metadata":{"execution":{"iopub.status.busy":"2024-01-22T17:41:21.938727Z","iopub.execute_input":"2024-01-22T17:41:21.939116Z","iopub.status.idle":"2024-01-22T17:41:22.345177Z","shell.execute_reply.started":"2024-01-22T17:41:21.939080Z","shell.execute_reply":"2024-01-22T17:41:22.344305Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"image_augmented, mask_augmented = augment_images()","metadata":{"execution":{"iopub.status.busy":"2024-01-22T17:41:22.347704Z","iopub.execute_input":"2024-01-22T17:41:22.348167Z","iopub.status.idle":"2024-01-22T17:41:25.423733Z","shell.execute_reply.started":"2024-01-22T17:41:22.348135Z","shell.execute_reply":"2024-01-22T17:41:25.422886Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from keras.layers import BatchNormalization, add\nfrom keras.layers import Conv2D\n\nkernel_initializer = 'he_uniform'\n\n\ndef conv_block_2D(x, filters, block_type, repeat=1, dilation_rate=1, size=3, padding='same'):\n    result = x\n\n    for i in range(0, repeat):\n\n        if block_type == 'separated':\n            result = separated_conv2D_block(result, filters, size=size, padding=padding)\n        elif block_type == 'duckv2':\n            result = duckv2_conv2D_block(result, filters, size=size)\n        elif block_type == 'midscope':\n            result = midscope_conv2D_block(result, filters)\n        elif block_type == 'widescope':\n            result = widescope_conv2D_block(result, filters)\n        elif block_type == 'resnet':\n            result = resnet_conv2D_block(result, filters, dilation_rate)\n        elif block_type == 'conv':\n            result = Conv2D(filters, (size, size),\n                            activation='relu', kernel_initializer=kernel_initializer, padding=padding)(result)\n        elif block_type == 'double_convolution':\n            result = double_convolution_with_batch_normalization(result, filters, dilation_rate)\n\n        else:\n            return None\n\n    return result\n\n\ndef duckv2_conv2D_block(x, filters, size):\n    x = BatchNormalization(axis=-1)(x)\n    x1 = widescope_conv2D_block(x, filters)\n\n    x2 = midscope_conv2D_block(x, filters)\n\n    x3 = conv_block_2D(x, filters, 'resnet', repeat=1)\n\n    x4 = conv_block_2D(x, filters, 'resnet', repeat=2)\n\n    x5 = conv_block_2D(x, filters, 'resnet', repeat=3)\n\n    x6 = separated_conv2D_block(x, filters, size=6, padding='same')\n\n    x = add([x1, x2, x3, x4, x5, x6])\n\n    x = BatchNormalization(axis=-1)(x)\n\n    return x\n\n\ndef separated_conv2D_block(x, filters, size=3, padding='same'):\n    x = Conv2D(filters, (1, size), activation='relu', kernel_initializer=kernel_initializer, padding=padding)(x)\n\n    x = BatchNormalization(axis=-1)(x)\n\n    x = Conv2D(filters, (size, 1), activation='relu', kernel_initializer=kernel_initializer, padding=padding)(x)\n\n    x = BatchNormalization(axis=-1)(x)\n\n    return x\n\n\ndef midscope_conv2D_block(x, filters):\n    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n               dilation_rate=1)(x)\n\n    x = BatchNormalization(axis=-1)(x)\n\n    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n               dilation_rate=2)(x)\n\n    x = BatchNormalization(axis=-1)(x)\n\n    return x\n\n\ndef widescope_conv2D_block(x, filters):\n    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n               dilation_rate=1)(x)\n\n    x = BatchNormalization(axis=-1)(x)\n\n    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n               dilation_rate=2)(x)\n\n    x = BatchNormalization(axis=-1)(x)\n\n    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n               dilation_rate=3)(x)\n\n    x = BatchNormalization(axis=-1)(x)\n\n    return x\n\n\ndef resnet_conv2D_block(x, filters, dilation_rate=1):\n    x1 = Conv2D(filters, (1, 1), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n                dilation_rate=dilation_rate)(x)\n\n    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n               dilation_rate=dilation_rate)(x)\n    x = BatchNormalization(axis=-1)(x)\n    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n               dilation_rate=dilation_rate)(x)\n    x = BatchNormalization(axis=-1)(x)\n    x_final = add([x, x1])\n\n    x_final = BatchNormalization(axis=-1)(x_final)\n\n    return x_final\n\n\ndef double_convolution_with_batch_normalization(x, filters, dilation_rate=1):\n    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n               dilation_rate=dilation_rate)(x)\n    x = BatchNormalization(axis=-1)(x)\n    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n               dilation_rate=dilation_rate)(x)\n    x = BatchNormalization(axis=-1)(x)\n\n    return x","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-22T17:41:25.425276Z","iopub.execute_input":"2024-01-22T17:41:25.425626Z","iopub.status.idle":"2024-01-22T17:41:29.245995Z","shell.execute_reply.started":"2024-01-22T17:41:25.425598Z","shell.execute_reply":"2024-01-22T17:41:29.244910Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.layers import add , Softmax\nfrom keras.models import Model\nfrom keras.layers import Conv2D, UpSampling2D\n\n\ndef create_multi_head_attention(query, key, value, h=8**-0.5):\n    query_shape, key_shape, value_shape = query.shape, key.shape, value.shape\n    d_model = query_shape[-1]\n    hw = value_shape[1] // query_shape[1]\n    \n    key = UpSampling2D((2,2) , interpolation='bicubic')(key)\n    key = Conv2D(d_model , (1,1) , activation=\"relu\" , padding=\"same\")(key)\n    value = Conv2D(value_shape[3] , (2,2), strides= hw, padding='same')(value)\n\n    score = tf.matmul(query, key, transpose_b=True)*h\n    score = tf.nn.softmax(score)\n\n    output = tf.matmul(score , value)\n    output = tf.nn.softmax(output)\n       \n    final = output * value\n\n    return final\n","metadata":{"execution":{"iopub.status.busy":"2024-01-22T17:41:29.247198Z","iopub.execute_input":"2024-01-22T17:41:29.247791Z","iopub.status.idle":"2024-01-22T17:41:29.256858Z","shell.execute_reply.started":"2024-01-22T17:41:29.247761Z","shell.execute_reply":"2024-01-22T17:41:29.255904Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"kernel_initializer = 'he_uniform'\ninterpolation = \"nearest\"\n\n\n\ndef create_model(img_height, img_width, input_chanels, out_classes, starting_filters):\n    input_layer = tf.keras.layers.Input((img_height, img_width, input_chanels))\n\n    print('Starting DUCK-Net')\n\n    p1 = Conv2D(starting_filters * 2, 2, strides=2, padding='same')(input_layer)\n    p2 = Conv2D(starting_filters * 4, 2, strides=2, padding='same')(p1)\n    p3 = Conv2D(starting_filters * 8, 2, strides=2, padding='same')(p2)\n    p4 = Conv2D(starting_filters * 16, 2, strides=2, padding='same')(p3)\n    p5 = Conv2D(starting_filters * 32, 2, strides=2, padding='same')(p4)\n\n    t0 = conv_block_2D(input_layer, starting_filters, 'duckv2', repeat=1)\n\n    l1i = Conv2D(starting_filters * 2, 2, strides=2, padding='same')(t0)\n    s1 = add([l1i, p1])\n    t1 = conv_block_2D(s1, starting_filters * 2, 'duckv2', repeat=1)\n\n    l2i = Conv2D(starting_filters * 4, 2, strides=2, padding='same')(t1)\n    s2 = add([l2i, p2])\n    t2 = conv_block_2D(s2, starting_filters * 4, 'duckv2', repeat=1)\n\n    l3i = Conv2D(starting_filters * 8, 2, strides=2, padding='same')(t2)\n    s3 = add([l3i, p3])\n    t3 = conv_block_2D(s3, starting_filters * 8, 'duckv2', repeat=1)\n\n    l4i = Conv2D(starting_filters * 16, 2, strides=2, padding='same')(t3)\n    s4 = add([l4i, p4])\n    t4 = conv_block_2D(s4, starting_filters * 16, 'duckv2', repeat=1)\n\n    l5i = Conv2D(starting_filters * 32, 2, strides=2, padding='same')(t4)\n    s5 = add([l5i, p5])\n    t51 = conv_block_2D(s5, starting_filters * 32, 'resnet', repeat=2)\n    t53 = conv_block_2D(t51, starting_filters * 16, 'resnet', repeat=2)\n    \n    #----------------------------------------------------------------------------------#\n\n    l5o = UpSampling2D((2, 2), interpolation=interpolation)(t53)\n    c4 = add([l5o, t4])\n    q4 = conv_block_2D(c4, starting_filters * 8, 'duckv2', repeat=1)\n    \n\n    l4o = UpSampling2D((2, 2), interpolation=interpolation)(q4)\n    c3 = add([l4o, t3])\n    q3 = conv_block_2D(c3, starting_filters * 4, 'duckv2', repeat=1)\n\n\n    l3o = UpSampling2D((2, 2), interpolation=interpolation)(q3)\n    c2 = add([l3o, t2])\n    q6 = conv_block_2D(c2, starting_filters * 2, 'duckv2', repeat=1)\n    #print(q6.shape)\n    \n    l2o = UpSampling2D((2, 2), interpolation=interpolation)(q6)\n    c1 = add([l2o, t1])\n    q1 = conv_block_2D(c1, starting_filters, 'duckv2', repeat=1)\n    #print(q1.shape)\n\n    l1o = UpSampling2D((2, 2), interpolation=interpolation)(q1)\n    c0 = add([l1o, t0])\n    z1 = conv_block_2D(c0, starting_filters, 'duckv2', repeat=1)\n    #print(z1.shape)\n\n    #output = Conv2D(out_classes, (1, 1), activation='sigmoid')(z1)\n    mha1 = create_multi_head_attention(c4 , t53 , z1)\n    mha2 = create_multi_head_attention(c3 , mha1 , z1)\n    mha3 = create_multi_head_attention(c2 , mha2 , z1)\n    mha4 = create_multi_head_attention(c1 , mha3 , z1)\n    \n    mha5 = UpSampling2D((2, 2), interpolation=interpolation)(mha4)\n    \n    final = conv_block_2D(mha5, starting_filters, 'duckv2', repeat=1)\n    print(final.shape)\n    \n    output = Conv2D(out_classes, (1, 1), activation='sigmoid')(final)\n    \n    model = Model(inputs=input_layer, outputs=output)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-01-22T17:41:29.258983Z","iopub.execute_input":"2024-01-22T17:41:29.259421Z","iopub.status.idle":"2024-01-22T17:41:29.282618Z","shell.execute_reply.started":"2024-01-22T17:41:29.259383Z","shell.execute_reply":"2024-01-22T17:41:29.281637Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = create_model(img_height=256, img_width=256, input_chanels=3, out_classes=1, starting_filters=17)","metadata":{"execution":{"iopub.status.busy":"2024-01-22T17:41:29.283828Z","iopub.execute_input":"2024-01-22T17:41:29.284144Z","iopub.status.idle":"2024-01-22T17:41:37.702043Z","shell.execute_reply.started":"2024-01-22T17:41:29.284107Z","shell.execute_reply":"2024-01-22T17:41:37.700728Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Starting DUCK-Net\n(None, 256, 256, 17)\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras.backend as K\nimport tensorflow as tf\n\n\ndef dice_metric_loss(ground_truth, predictions, smooth=1e-6):\n    ground_truth = K.cast(ground_truth, tf.float32)\n    predictions = K.cast(predictions, tf.float32)\n    ground_truth = K.flatten(ground_truth)\n    predictions = K.flatten(predictions)\n    intersection = K.sum(predictions * ground_truth)\n    union = K.sum(predictions) + K.sum(ground_truth)\n\n    dice = (2. * intersection + smooth) / (union + smooth)\n\n    return 1 - dice","metadata":{"execution":{"iopub.status.busy":"2024-01-22T17:41:37.703337Z","iopub.execute_input":"2024-01-22T17:41:37.703630Z","iopub.status.idle":"2024-01-22T17:41:37.710105Z","shell.execute_reply.started":"2024-01-22T17:41:37.703604Z","shell.execute_reply":"2024-01-22T17:41:37.709180Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"learning_rate = 1e-4\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\nmodel.compile(optimizer=optimizer, loss=dice_metric_loss , metrics=['acc'])","metadata":{"execution":{"iopub.status.busy":"2024-01-22T17:45:18.832492Z","iopub.execute_input":"2024-01-22T17:45:18.832940Z","iopub.status.idle":"2024-01-22T17:45:18.885297Z","shell.execute_reply.started":"2024-01-22T17:45:18.832892Z","shell.execute_reply":"2024-01-22T17:45:18.883819Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import gc\nEPOCHS = 50\nmin_loss_for_saving = 0.3\nstep = 0\n\nfor epoch in range(0, EPOCHS):\n    \n    print(f'Training, epoch {epoch}')\n    print('Learning Rate: ' + str(learning_rate))\n\n    step += 1\n    \n    model.fit(x=image_augmented, y=mask_augmented, epochs=1, batch_size=4, validation_data=(x_valid, y_valid), verbose=1 )\n    \n    prediction_valid = model.predict(x_valid, verbose=0)\n    loss_valid = dice_metric_loss(y_valid, prediction_valid)\n    \n    loss_valid = loss_valid.numpy()\n    print(\"Loss Validation: \" + str(loss_valid))\n        \n    prediction_test = model.predict(x_test, verbose=0)\n    loss_test = dice_metric_loss(y_test, prediction_test)\n    loss_test = loss_test.numpy()\n    print(\"Loss Test: \" + str(loss_test))\n     \n    if min_loss_for_saving > loss_valid:\n        min_loss_for_saving = loss_valid\n        print(\"Saved model with val_loss: \", loss_valid)\n        model.save(\"/kaggle/working/duck-net-multi-head.h5\")\n        \n    #del image_augmented\n    #del mask_augmented\n\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-01-22T17:45:21.806881Z","iopub.execute_input":"2024-01-22T17:45:21.807224Z","iopub.status.idle":"2024-01-22T18:40:02.451439Z","shell.execute_reply.started":"2024-01-22T17:45:21.807199Z","shell.execute_reply":"2024-01-22T18:40:02.450394Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Training, epoch 0\nLearning Rate: 0.0001\n122/122 [==============================] - 301s 517ms/step - loss: 0.9092 - acc: 0.6426 - val_loss: 0.9439 - val_acc: 0.0899\nLoss Validation: 0.9473002\nLoss Test: 0.93337774\nTraining, epoch 1\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 444ms/step - loss: 0.8730 - acc: 0.7815 - val_loss: 0.8239 - val_acc: 0.9497\nLoss Validation: 0.94722456\nLoss Test: 0.9332843\nTraining, epoch 2\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 443ms/step - loss: 0.8470 - acc: 0.8433 - val_loss: 0.7414 - val_acc: 0.9394\nLoss Validation: 0.9472006\nLoss Test: 0.933247\nTraining, epoch 3\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 442ms/step - loss: 0.8210 - acc: 0.8820 - val_loss: 0.7886 - val_acc: 0.8934\nLoss Validation: 0.9472032\nLoss Test: 0.93324906\nTraining, epoch 4\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 443ms/step - loss: 0.7991 - acc: 0.9067 - val_loss: 0.7316 - val_acc: 0.9152\nLoss Validation: 0.94710964\nLoss Test: 0.9330019\nTraining, epoch 5\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 443ms/step - loss: 0.7761 - acc: 0.9227 - val_loss: 0.7303 - val_acc: 0.9343\nLoss Validation: 0.9452353\nLoss Test: 0.9303169\nTraining, epoch 6\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 442ms/step - loss: 0.7543 - acc: 0.9340 - val_loss: 0.7167 - val_acc: 0.9499\nLoss Validation: 0.95290506\nLoss Test: 0.9575196\nTraining, epoch 7\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 441ms/step - loss: 0.7291 - acc: 0.9443 - val_loss: 0.6426 - val_acc: 0.9499\nLoss Validation: 0.9455084\nLoss Test: 0.935554\nTraining, epoch 8\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.7024 - acc: 0.9529 - val_loss: 0.6446 - val_acc: 0.9459\nLoss Validation: 0.94408166\nLoss Test: 0.9331952\nTraining, epoch 9\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.6756 - acc: 0.9593 - val_loss: 0.5713 - val_acc: 0.9727\nLoss Validation: 0.8778517\nLoss Test: 0.85499597\nTraining, epoch 10\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 439ms/step - loss: 0.6500 - acc: 0.9654 - val_loss: 0.5374 - val_acc: 0.9766\nLoss Validation: 0.8657788\nLoss Test: 0.87839437\nTraining, epoch 11\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.6171 - acc: 0.9696 - val_loss: 0.5325 - val_acc: 0.9874\nLoss Validation: 0.9250791\nLoss Test: 0.9209622\nTraining, epoch 12\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 439ms/step - loss: 0.5863 - acc: 0.9745 - val_loss: 0.4976 - val_acc: 0.9845\nLoss Validation: 0.9327512\nLoss Test: 0.9497415\nTraining, epoch 13\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.5697 - acc: 0.9745 - val_loss: 0.4437 - val_acc: 0.9886\nLoss Validation: 0.8183806\nLoss Test: 0.7914454\nTraining, epoch 14\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.5211 - acc: 0.9795 - val_loss: 0.4202 - val_acc: 0.9874\nLoss Validation: 0.922908\nLoss Test: 0.91080856\nTraining, epoch 15\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.4896 - acc: 0.9823 - val_loss: 0.3800 - val_acc: 0.9903\nLoss Validation: 0.7109479\nLoss Test: 0.61575073\nTraining, epoch 16\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.4614 - acc: 0.9834 - val_loss: 0.3282 - val_acc: 0.9918\nLoss Validation: 0.69909596\nLoss Test: 0.65154445\nTraining, epoch 17\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 439ms/step - loss: 0.4404 - acc: 0.9849 - val_loss: 0.3262 - val_acc: 0.9887\nLoss Validation: 0.7840196\nLoss Test: 0.7572993\nTraining, epoch 18\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 439ms/step - loss: 0.4063 - acc: 0.9864 - val_loss: 0.3423 - val_acc: 0.9911\nLoss Validation: 0.7478403\nLoss Test: 0.70999503\nTraining, epoch 19\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.3827 - acc: 0.9881 - val_loss: 0.2684 - val_acc: 0.9921\nLoss Validation: 0.7804524\nLoss Test: 0.74279594\nTraining, epoch 20\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 441ms/step - loss: 0.3468 - acc: 0.9888 - val_loss: 0.2473 - val_acc: 0.9930\nLoss Validation: 0.43866324\nLoss Test: 0.45140427\nTraining, epoch 21\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.3510 - acc: 0.9896 - val_loss: 0.2932 - val_acc: 0.9914\nLoss Validation: 0.7727503\nLoss Test: 0.7383697\nTraining, epoch 22\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.3201 - acc: 0.9898 - val_loss: 0.2196 - val_acc: 0.9928\nLoss Validation: 0.5047983\nLoss Test: 0.40178704\nTraining, epoch 23\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 441ms/step - loss: 0.3173 - acc: 0.9891 - val_loss: 0.3644 - val_acc: 0.9880\nLoss Validation: 0.7348364\nLoss Test: 0.72478163\nTraining, epoch 24\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 441ms/step - loss: 0.2884 - acc: 0.9908 - val_loss: 0.2990 - val_acc: 0.9907\nLoss Validation: 0.88359344\nLoss Test: 0.907868\nTraining, epoch 25\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.2700 - acc: 0.9913 - val_loss: 0.2247 - val_acc: 0.9926\nLoss Validation: 0.4196248\nLoss Test: 0.51391464\nTraining, epoch 26\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.2747 - acc: 0.9911 - val_loss: 0.2134 - val_acc: 0.9931\nLoss Validation: 0.6319871\nLoss Test: 0.6826705\nTraining, epoch 27\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.2460 - acc: 0.9919 - val_loss: 0.2456 - val_acc: 0.9915\nLoss Validation: 0.7325134\nLoss Test: 0.7106402\nTraining, epoch 28\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.2359 - acc: 0.9922 - val_loss: 0.2524 - val_acc: 0.9906\nLoss Validation: 0.65769213\nLoss Test: 0.7265291\nTraining, epoch 29\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.2344 - acc: 0.9922 - val_loss: 0.2476 - val_acc: 0.9912\nLoss Validation: 0.6903515\nLoss Test: 0.64948565\nTraining, epoch 30\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 439ms/step - loss: 0.2216 - acc: 0.9923 - val_loss: 0.2168 - val_acc: 0.9918\nLoss Validation: 0.58036304\nLoss Test: 0.5260396\nTraining, epoch 31\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.2283 - acc: 0.9926 - val_loss: 0.1908 - val_acc: 0.9928\nLoss Validation: 0.5011482\nLoss Test: 0.41782945\nTraining, epoch 32\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 439ms/step - loss: 0.2159 - acc: 0.9925 - val_loss: 0.2970 - val_acc: 0.9888\nLoss Validation: 0.88687867\nLoss Test: 0.90324795\nTraining, epoch 33\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.2066 - acc: 0.9928 - val_loss: 0.2229 - val_acc: 0.9915\nLoss Validation: 0.40814787\nLoss Test: 0.32239926\nTraining, epoch 34\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.1973 - acc: 0.9929 - val_loss: 0.2221 - val_acc: 0.9916\nLoss Validation: 0.45411795\nLoss Test: 0.5334913\nTraining, epoch 35\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.1978 - acc: 0.9929 - val_loss: 0.1951 - val_acc: 0.9926\nLoss Validation: 0.24306\nLoss Test: 0.23296499\nSaved model with val_loss:  0.24306\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"Training, epoch 36\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 441ms/step - loss: 0.1781 - acc: 0.9933 - val_loss: 0.1510 - val_acc: 0.9941\nLoss Validation: 0.5612525\nLoss Test: 0.5411109\nTraining, epoch 37\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.1845 - acc: 0.9937 - val_loss: 0.2006 - val_acc: 0.9924\nLoss Validation: 0.33423382\nLoss Test: 0.37401915\nTraining, epoch 38\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.1876 - acc: 0.9932 - val_loss: 0.1655 - val_acc: 0.9929\nLoss Validation: 0.4184602\nLoss Test: 0.42941678\nTraining, epoch 39\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 440ms/step - loss: 0.1879 - acc: 0.9932 - val_loss: 0.1628 - val_acc: 0.9933\nLoss Validation: 0.33922565\nLoss Test: 0.25621498\nTraining, epoch 40\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 439ms/step - loss: 0.1721 - acc: 0.9939 - val_loss: 0.1812 - val_acc: 0.9926\nLoss Validation: 0.81376374\nLoss Test: 0.7867111\nTraining, epoch 41\nLearning Rate: 0.0001\n122/122 [==============================] - 53s 439ms/step - loss: 0.1883 - acc: 0.9933 - val_loss: 0.2367 - val_acc: 0.9905\nLoss Validation: 0.5729013\nLoss Test: 0.6228696\nTraining, epoch 42\nLearning Rate: 0.0001\n122/122 [==============================] - 53s 439ms/step - loss: 0.1696 - acc: 0.9938 - val_loss: 0.1871 - val_acc: 0.9923\nLoss Validation: 0.434771\nLoss Test: 0.45998174\nTraining, epoch 43\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 439ms/step - loss: 0.1657 - acc: 0.9939 - val_loss: 0.1649 - val_acc: 0.9933\nLoss Validation: 0.30674326\nLoss Test: 0.28218305\nTraining, epoch 44\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 439ms/step - loss: 0.1678 - acc: 0.9938 - val_loss: 0.1812 - val_acc: 0.9926\nLoss Validation: 0.34359097\nLoss Test: 0.3207791\nTraining, epoch 45\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 439ms/step - loss: 0.1554 - acc: 0.9939 - val_loss: 0.2106 - val_acc: 0.9914\nLoss Validation: 0.34079355\nLoss Test: 0.3108548\nTraining, epoch 46\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 439ms/step - loss: 0.1546 - acc: 0.9942 - val_loss: 0.1540 - val_acc: 0.9934\nLoss Validation: 0.4488719\nLoss Test: 0.574304\nTraining, epoch 47\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 439ms/step - loss: 0.1578 - acc: 0.9936 - val_loss: 0.1543 - val_acc: 0.9935\nLoss Validation: 0.6918324\nLoss Test: 0.68258524\nTraining, epoch 48\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 441ms/step - loss: 0.1630 - acc: 0.9938 - val_loss: 0.1429 - val_acc: 0.9936\nLoss Validation: 0.5667994\nLoss Test: 0.50223595\nTraining, epoch 49\nLearning Rate: 0.0001\n122/122 [==============================] - 54s 439ms/step - loss: 0.1620 - acc: 0.9938 - val_loss: 0.1477 - val_acc: 0.9936\nLoss Validation: 0.68885416\nLoss Test: 0.6925752\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import jaccard_score, precision_score, recall_score, accuracy_score, f1_score\nprint(\"Loading the model\")\n\nmodel = tf.keras.models.load_model('/kaggle/working/duck-net-multi-head.h5', custom_objects={'dice_metric_loss':dice_metric_loss})\n\nprediction_train = model.predict(x_train, batch_size=4)\nprediction_valid = model.predict(x_valid, batch_size=4)\nprediction_test = model.predict(x_test, batch_size=4)\n\nprint(\"Predictions done\")\n\ndice_train = f1_score(np.ndarray.flatten(np.array(y_train, dtype=bool)),\n                           np.ndarray.flatten(prediction_train > 0.5))\ndice_test = f1_score(np.ndarray.flatten(np.array(y_test, dtype=bool)),\n                          np.ndarray.flatten(prediction_test > 0.5))\ndice_valid = f1_score(np.ndarray.flatten(np.array(y_valid, dtype=bool)),\n                           np.ndarray.flatten(prediction_valid > 0.5))\n\nprint(\"Dice finished\")\n\n\nmiou_train = jaccard_score(np.ndarray.flatten(np.array(y_train, dtype=bool)),\n                           np.ndarray.flatten(prediction_train > 0.5))\nmiou_test = jaccard_score(np.ndarray.flatten(np.array(y_test, dtype=bool)),\n                          np.ndarray.flatten(prediction_test > 0.5))\nmiou_valid = jaccard_score(np.ndarray.flatten(np.array(y_valid, dtype=bool)),\n                           np.ndarray.flatten(prediction_valid > 0.5))\n\nprint(\"Miou finished\")\n\n\nprecision_train = precision_score(np.ndarray.flatten(np.array(y_train, dtype=bool)),\n                                  np.ndarray.flatten(prediction_train > 0.5))\nprecision_test = precision_score(np.ndarray.flatten(np.array(y_test, dtype=bool)),\n                                 np.ndarray.flatten(prediction_test > 0.5))\nprecision_valid = precision_score(np.ndarray.flatten(np.array(y_valid, dtype=bool)),\n                                  np.ndarray.flatten(prediction_valid > 0.5))\n\nprint(\"Precision finished\")\n\n\nrecall_train = recall_score(np.ndarray.flatten(np.array(y_train, dtype=bool)),\n                            np.ndarray.flatten(prediction_train > 0.5))\nrecall_test = recall_score(np.ndarray.flatten(np.array(y_test, dtype=bool)),\n                           np.ndarray.flatten(prediction_test > 0.5))\nrecall_valid = recall_score(np.ndarray.flatten(np.array(y_valid, dtype=bool)),\n                            np.ndarray.flatten(prediction_valid > 0.5))\n\nprint(\"Recall finished\")\n\n\naccuracy_train = accuracy_score(np.ndarray.flatten(np.array(y_train, dtype=bool)),\n                                np.ndarray.flatten(prediction_train > 0.5))\naccuracy_test = accuracy_score(np.ndarray.flatten(np.array(y_test, dtype=bool)),\n                               np.ndarray.flatten(prediction_test > 0.5))\naccuracy_valid = accuracy_score(np.ndarray.flatten(np.array(y_valid, dtype=bool)),\n                                np.ndarray.flatten(prediction_valid > 0.5))\n\n\nprint(\"Accuracy finished\")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:40:55.578220Z","iopub.execute_input":"2024-01-22T18:40:55.578660Z","iopub.status.idle":"2024-01-22T18:42:28.907991Z","shell.execute_reply.started":"2024-01-22T18:40:55.578628Z","shell.execute_reply":"2024-01-22T18:42:28.906999Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Loading the model\n122/122 [==============================] - 20s 112ms/step\n16/16 [==============================] - 8s 112ms/step\n16/16 [==============================] - 2s 109ms/step\nPredictions done\nDice finished\nMiou finished\nPrecision finished\nRecall finished\nAccuracy finished\n","output_type":"stream"}]},{"cell_type":"code","source":"final_file = '/kaggle/working/'+'results_'+'Multi_Head_DUCK-Net'+ '.txt'\nprint(final_file)\n\nwith open(final_file, 'a') as f:\n    f.write('clinic-db' + '\\n\\n')\n    f.write('dice_train: ' + str(dice_train) + ' dice_valid: ' + str(dice_valid) + ' dice_test: ' + str(dice_test) + '\\n\\n')\n    f.write('miou_train: ' + str(miou_train) + ' miou_valid: ' + str(miou_valid) + ' miou_test: ' + str(miou_test) + '\\n\\n')\n    f.write('precision_train: ' + str(precision_train) + ' precision_valid: ' + str(precision_valid) + ' precision_test: ' + str(precision_test) + '\\n\\n')\n    f.write('recall_train: ' + str(recall_train) + ' recall_valid: ' + str(recall_valid) + ' recall_test: ' + str(recall_test) + '\\n\\n')\n    f.write('accuracy_train: ' + str(accuracy_train) + ' accuracy_valid: ' + str(accuracy_valid) + ' accuracy_test: ' + str(accuracy_test) + '\\n\\n\\n\\n')\n\nprint('File done')","metadata":{"execution":{"iopub.status.busy":"2024-01-22T18:42:56.591508Z","iopub.execute_input":"2024-01-22T18:42:56.592206Z","iopub.status.idle":"2024-01-22T18:42:56.600737Z","shell.execute_reply.started":"2024-01-22T18:42:56.592173Z","shell.execute_reply":"2024-01-22T18:42:56.599828Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"/kaggle/working/results_Multi_Head_DUCK-Net.txt\nFile done\n","output_type":"stream"}]}]}